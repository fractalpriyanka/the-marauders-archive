# üìö RAG Storybook ‚Äî The Marauder‚Äôs Archive

A RAG-based question-answering system that lets users explore the entire Harry Potter collection through natural-language queries, returning answers grounded in the original text rather than speculative outputs.

The system loads PDFs, chunks and embeds content, indexes it with FAISS, retrieves relevant passages, and generates citation-supported responses using Google Gemini.

---

## Demo

![Demo](app/assets/screenrec.gif)

### ‚ö†Ô∏è Token Limit (Gemini)

This project uses **Gemini**, which has a limit on the total tokens per request (input + output).  
Very long queries or large retrieved context may be trimmed, truncated, or rejected ‚Äî which can occasionally reduce answer quality.

> Keep questions short and avoid pasting long text or full chapters.


### üëâ **Try the app here:**
[![Open in Streamlit](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://the-marauders-archive-ggdwufkz7ku8wi8qrulappg.streamlit.app/)

---

### üöÄ Features

üìÑ Load very large PDFs (multi-book collections)

üîç Smart sentence + chapter-aware chunking

üß† High-quality embeddings (all-mpnet-base-v2)

‚ö° Fast semantic search using FAISS

ü§ñ Answer generation using Google-GenAI

üß™ Retrieval evaluation (Recall@K)

üåê Streamlit interface (ready for deployment)

üìé Persistent pipeline files (pages.json, chunks.json, index.faiss)

---

### üóÇÔ∏è Project Structure

```text
rag_storybook/
‚îÇ
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îî‚îÄ‚îÄ main.py
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/
‚îÇ   ‚îú‚îÄ‚îÄ chunking/
‚îÇ   ‚îú‚îÄ‚îÄ embeddings/
‚îÇ   ‚îú‚îÄ‚îÄ retrieval/
‚îÇ   ‚îú‚îÄ‚îÄ generation/
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ settings.py
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îî‚îÄ‚îÄ processed/
‚îÇ
‚îú‚îÄ‚îÄ evaluation/
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md

```

### üçÅ RAG ARCHITECTURE

```text
PDF
 ‚îÇ
 ‚ñº
Extract Pages  ‚Äî (pdfplumber + regex)
 ‚îÇ
 ‚ñº
Chunk Pages ‚Äî (chapter-aware + sliding window)
 ‚îÇ
 ‚ñº
Embeddings ‚Äî (all-mpnet-base-v2)
 ‚îÇ
 ‚ñº
FAISS Index ‚Äî (IndexFlatIP, cosine)
 ‚îÇ
 ‚ñº
User Question
 ‚îÇ
 ‚ñº
Retrieve ‚Äî (FAISS + neighbors + lexical boost)
 ‚îÇ
 ‚ñº
Gemini Answer ‚Äî (grounded, no hallucinations)

```

### ‚öôÔ∏è 1Ô∏è‚É£ Installation

**Create and activate a virtual environment:**

- python -m venv my_venv
- source my_venv/bin/activate # Windows: my_venv\Scripts\activate

**Install dependencies:**

- pip install -r requirements.txt

### üîë 2Ô∏è‚É£ Environment Variables

**Create a .env file in the project root:**

- GEMINI_API_KEY=your_key_here

### üßæ 3Ô∏è‚É£ Pipeline ‚Äî Step by Step

**3.1 Load PDF ‚Üí pages.json**

- python -m src.ingestion.pdf_loader --> data/processed/pages.json

```json
{
  "page_no": 2,
  "book": "Harry Potter and the Sorcerer's Stone",
  "chapter": "CHAPTER ONE: The Boy Who Lived",
  "text": "The Dursleys had everything they wanted..."
}
```

**3.2 Chunk Pages ‚Üí chunks.json**

- python -m src.chunking.chunker --> data/processed/chunks.json

```json
{
  "chunk_id": 6,
  "text": "couldn‚Äôt help....",
  "book": "Harry Potter and the Sorcerer‚Äôs Stone",
  "chapter": "CHAPTER ONE: THE BOY WHO LIVED",
  "chapter_id": 0,
  "page_no": 12
}
```

**3.3 Generate Embeddings ‚Üí Build Index**

- python -m src.embeddings.embedder --> data/processed/index.faiss
- Uses: Sentence-Transformers ‚Äî all-mpnet-base-v2

**3.4 Retrieval (FAISS + Context Expansion)**

When a user asks a question:

1Ô∏è‚É£ encode query
2Ô∏è‚É£ search FAISS
3Ô∏è‚É£ expand neighboring chunks (chapter-aware)
4Ô∏è‚É£ return ranked results

**3.5 Answer Generation (Google-GenAI)**

Retrieval text ‚Üí LLM prompt ‚Üí grounded answer.

No hallucinations ‚Äî answer must come from retrieved context.

### üß™ 4Ô∏è‚É£ Evaluation

**Run evaluation:**

- python -m evaluation.evaluate_retrieval
- Outputs metrics: Recall@K -- Found / Missing questions

### üåç 5Ô∏è‚É£ Run the App (Streamlit)

- streamlit run app/main.py



---

## üê¶‚Äç‚¨õ Harry Potter RAG System ‚Äì Evaluation Report

### Project Overview

This document summarizes the evaluation of a Retrieval-Augmented Generation (RAG) system built on the complete Harry Potter book series (Books 1‚Äì7).
The evaluation focuses on retrieval quality, grounding, and reliability, not memorization or trivia.

**System**: Harry Potter RAG
**Source Material**: Harry Potter Complete Series (Books 1‚Äì7)
**Evaluation Dataset**: 20 curated book-only questions

### Evaluation Methodology

#### Test Dataset Composition

The system was tested across multiple question paradigms to reflect real narrative QA behavior:

```text

| Paradigm               | Count | Description                           |
| ---------------------- | ----- | ------------------------------------- |
| **Explicit Facts**     | 5     | Direct, clearly stated facts          |
| **Rare Facts**         | 4     | Details mentioned once or formally    |
| **Emergent Narrative** | 4     | Facts requiring cross-chapter context |
| **Locations**          | 4     | Spatial and setting questions         |
| **Poems / Songs**      | 2     | Structured verse content              |
| **Boundary Cases**     | 1     | Out-of-scope (should refuse)          |
```

#### Key Results

#### Overall Metrics

```text
| Metric                     | Score    | Status      |
| -------------------------- | -------- | ----------- |
| **Retrieval Recall@K**     | **73%**  | ‚úÖ Decent    |
| **Explicit Fact Accuracy** | High     | ‚úÖ Strong    |
| **Rare / Emergent Facts**  | Moderate | ‚ö†Ô∏è Expected |
| **Hallucination Rate**     | Low      | ‚úÖ Safe      |
| **Correct Refusals**       | 100%     | ‚úÖ Correct   |
```

#### Performance by Paradigm

```text

| Question Type      | Correct / Total | Notes                        |
| ------------------ | --------------- | ---------------------------- |
| Explicit Facts     | 5 / 5           | Reliable retrieval           |
| Rare Facts         | 2 / 4           | Single-mention limitation    |
| Emergent Narrative | 2 / 4           | Multi-hop reasoning required |
| Locations          | 3 / 4           | Phrasing sensitivity         |
| Poems / Songs      | 2 / 2           | Chunking effective           |
| Boundary Case      | 1 / 1           | Proper refusal               |
```


#### Detailed Analysis
##### Strengths
* ‚úÖ Strong performance on explicit facts and object/entity queries
* ‚úÖ Successful retrieval of songs and poems
* ‚úÖ Low hallucination rate due to strict grounding
* ‚úÖ Correct handling of out-of-scope questions

##### Weaknesses
* ‚ùå Rare facts mentioned only once (e.g., full formal names)
* ‚ùå Emergent facts requiring synthesis across distant chapters
* ‚ùå Location questions with varied phrasing

These failures are expected for narrative RAG systems and do not indicate architectural flaws.

#### Interpretation & Insights

**What This Evaluation Measures**
* ‚úÖ Retrieval quality (Recall@K)
* ‚úÖ Grounded answer generation
* ‚úÖ Faithfulness to source material
* ‚úÖ Refusal behavior for missing context

### Conclusion

With a Retrieval Recall@K of 0.73, the Harry Potter RAG system demonstrates solid and realistic performance for a long, narrative, multi-book corpus.

**Key takeaway:**

The system prioritizes faithfulness over fluency, correctly refusing uncertain answers rather than hallucinating ‚Äî the desired behavior for a trustworthy RAG system.

### üìå Configuration ‚Äî settings.py

**Central control over:**

- paths

- chunking

- embedding model

- FAISS parameters

- Gemini model

- TOP-K retrieval

### üîß Improving Retrieval (Optional Enhancements)

- tune chunk size + overlap

- add title/heading boosting

- try hybrid (keyword + vector) search

- filter irrelevant passages before LLM

- increase context window slightly

### ü§ù Credits

**Built with:**

- Sentence-Transformers

- FAISS

- Google-GenAI

- Streamlit

- Python

Inspired by classic RAG architecture ‚Äî adapted for large storybooks.

#### üìÑ License

Educational / personal use only.
Content belongs to original copyright holders.
